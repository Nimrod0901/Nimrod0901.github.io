<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8">
  
  <title>手写KNN | Nimrod&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="KNN原理KNN又称K邻近，是一种基本分类与回归方法，通过找到与待测样本距离最近的K个样本，然后把这K个样本中标签出现次数最多的标签作为预测值。 数据集Mnist数据集，通过Tenserflow导入，样本规模是 28 * 28的矩阵，训练集大小是60000， 测试集的大小是10000 实现导入数据因为数据量比较大，二值化方便计算，并且将二维的矩阵扁平化，使得训练样本变为784维的矩阵。 def l">
<meta property="og:type" content="article">
<meta property="og:title" content="手写KNN">
<meta property="og:url" content="http://nimrod.life/2019/03/21/HandWrtingKNN/index.html">
<meta property="og:site_name" content="Nimrod&#39;s blog">
<meta property="og:description" content="KNN原理KNN又称K邻近，是一种基本分类与回归方法，通过找到与待测样本距离最近的K个样本，然后把这K个样本中标签出现次数最多的标签作为预测值。 数据集Mnist数据集，通过Tenserflow导入，样本规模是 28 * 28的矩阵，训练集大小是60000， 测试集的大小是10000 实现导入数据因为数据量比较大，二值化方便计算，并且将二维的矩阵扁平化，使得训练样本变为784维的矩阵。 def l">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://nimrod.life/img/KNNres.jpg">
<meta property="article:published_time" content="2019-03-21T08:37:29.000Z">
<meta property="article:modified_time" content="2020-08-21T01:32:02.321Z">
<meta property="article:author" content="Nimrod">
<meta property="article:tag" content="K邻近算法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://nimrod.life/img/KNNres.jpg">
  
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  
<link rel="stylesheet" href="/css/typing.css">

  
<link rel="stylesheet" href="/css/donate.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1/css/fork-awesome.min.css">

  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.0.2"></head>

  
    
      <body>
    
  
      <div id="container" class="container">
        <article id="post-HandWrtingKNN" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <header id="header" class="header">
  <nav class="mobile-nav">
    <h1 class="nickname">Nimrod&#39;s Blog</h1>
    <ul class="mobile-nav-menu">
      <label for="mobile-menu-toggle"><a id="menu-button">&#9776; Menu</a></label>
      <input type="checkbox" id="mobile-menu-toggle"/>
      <ul class="mobile-nav-link">
        
        <a href="/">Home</a>
        
        <a href="/archives">Archives</a>
        
        <a href="/about">About</a>
        
        <a href="/demos">Demos</a>
        
      </ul>
    </ul>
  </nav>
	
		<nav id="main-nav" class="main-nav">
	
	
	  <a class="main-nav-link" href="/">Home</a>
	
	  <a class="main-nav-link" href="/archives">Archives</a>
	
	  <a class="main-nav-link" href="/about">About</a>
	
	  <a class="main-nav-link" href="/demos">Demos</a>
	
  </nav>
</header>

  <hr/>
  <div class="article-inner">
    

    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      手写KNN
    </h1>
  

      </header>
    
    <div class="e-content article-entry typo" itemprop="articleBody">
      
        <h1 id="KNN原理"><a href="#KNN原理" class="headerlink" title="KNN原理"></a>KNN原理</h1><p>KNN又称K邻近，是一种基本分类与回归方法，通过找到与待测样本距离最近的K个样本，然后把这K个样本中标签出现次数最多的标签作为预测值。</p>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p>Mnist数据集，通过Tenserflow导入，样本规模是 28 * 28的矩阵，训练集大小是60000， 测试集的大小是10000</p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="导入数据"><a href="#导入数据" class="headerlink" title="导入数据"></a>导入数据</h2><p>因为数据量比较大，二值化方便计算，并且将二维的矩阵扁平化，使得训练样本变为784维的矩阵。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadData</span>():</span></span><br><span class="line">    <span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">    mnist = tf.keras.datasets.mnist</span><br><span class="line">    (X_train, y_train),(X_test, y_test) = mnist.load_data()</span><br><span class="line">    X_train[X_train &gt;= <span class="number">127</span>] = <span class="number">1</span></span><br><span class="line">    X_train[X_train &lt; <span class="number">127</span>] = <span class="number">0</span></span><br><span class="line">    X_test[X_test &gt;= <span class="number">127</span>] = <span class="number">1</span></span><br><span class="line">    X_test[X_test &lt; <span class="number">127</span>] = <span class="number">0</span></span><br><span class="line">    <span class="comment"># X_train, X_test = X_train / 255.0, X_test / 255.0 # 标准化</span></span><br><span class="line">    X_train = X_train.reshape(X_train.shape[<span class="number">0</span>], X_train.size // X_train.shape[<span class="number">0</span>])</span><br><span class="line">    X_test = X_test.reshape(X_test.shape[<span class="number">0</span>], X_test.size // X_test.shape[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> X_train, X_test, y_train, y_test</span><br></pre></td></tr></table></figure>

<h2 id="KNN算法"><a href="#KNN算法" class="headerlink" title="KNN算法"></a>KNN算法</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 欧几里得距离</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclideanDistance</span>(<span class="params">x1, x2</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.square(x1-x2)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kNearestNeighbor</span>(<span class="params">X_train, y_train, vec, k=<span class="number">1</span>, kind=<span class="string">&#x27;eu&#x27;</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">        X_train: 训练数据集</span></span><br><span class="line"><span class="string">        y_train: 训练标签集</span></span><br><span class="line"><span class="string">        vec: 用于预测的数据</span></span><br><span class="line"><span class="string">        k: K值</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        预测标签</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    trainSize = X_train.shape[<span class="number">0</span>]</span><br><span class="line">    cls_cnt = &#123;&#125;  <span class="comment"># 用来判断测试数据属于哪个分类</span></span><br><span class="line">    <span class="keyword">if</span> kind == <span class="string">&#x27;eu&#x27;</span>:</span><br><span class="line">        <span class="comment"># 欧式距离</span></span><br><span class="line">        dist = np.apply_along_axis(euclideanDistance, <span class="number">1</span>, X_train, vec)  <span class="comment"># 这个函数帮助我们再每行应用计算距离 </span></span><br><span class="line">    <span class="keyword">if</span> kind == <span class="string">&#x27;ma&#x27;</span>:</span><br><span class="line">        <span class="comment"># 曼哈顿距离</span></span><br><span class="line">        dist = np.apply_along_axis(manhattanDistance, <span class="number">1</span>, X_train, vec)  <span class="comment"># 这个函数帮助我们再每行应用计算距离</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> el <span class="keyword">in</span> dist.argsort()[:k]:</span><br><span class="line">        cls_cnt[y_train[el]] = cls_cnt[y_train[el]] + <span class="number">1</span> <span class="keyword">if</span> y_train[el] <span class="keyword">in</span> cls_cnt <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> max(cls_cnt)</span><br></pre></td></tr></table></figure>

<h2 id="测试样本"><a href="#测试样本" class="headerlink" title="测试样本"></a>测试样本</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    err = <span class="number">0</span></span><br><span class="line">    testSize = X_test.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(testSize):</span><br><span class="line">        print(<span class="string">&#x27;Testing the &#123;&#125; data&#x27;</span>.format(i))</span><br><span class="line">    test_vec = X_test[i]</span><br><span class="line">    pred = kNearestNeighbor(X_train, y_train, test_vec, <span class="number">3</span>, kind=<span class="string">&#x27;eu&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> pred != y_test[i]:</span><br><span class="line">        err += <span class="number">1</span></span><br><span class="line">    acc = <span class="number">1</span> - err / testSize</span><br><span class="line">    print(acc)</span><br></pre></td></tr></table></figure>

<h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p><img src="/img/KNNres.jpg" alt=""><br>准确率为94.98%,效果还是可以的。</p>

      
      
    </div>
    <footer class="article-footer">
      <ul class="article-meta">
        <li>
          <span class="label">Published Date:</span>
          <a href="/2019/03/21/HandWrtingKNN/" class="article-date">
  <time class="dt-published" datetime="2019-03-21T08:37:29.000Z" itemprop="datePublished">2019-03-21</time>
</a>

        </li>
        
          <li>
            <span class="label">Category:</span>
            
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8A%80%E6%9C%AF%E5%90%91/">技术向</a>
  </div>


          </li>
        
        
          <li>
            <span class="label">Tag:</span>
            
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/K%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%95/" rel="tag">K邻近算法</a></li></ul>


          </li>
        
        <hr/>
      </ul>
    </footer>
  </div>
  
    
<nav id="article-nav" class="article-nav">
  
    <a href="/2019/03/29/sword-to-offer-3/" id="article-nav-newer" class="article-nav-link-wrap newer">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          剑指offer之从头到尾打印链表
        
      </div>
    </a>
  
  
    <a href="/2018/12/31/written-in-the-end/" id="article-nav-older" class="article-nav-link-wrap older">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">抓住2018的尾巴</div>
    </a>
  
</nav>


  
</article>










      </div>
      
    <footer id="footer" class="post-footer footer">
      
        <ul class="footer-links">
          
            <li><a href="/archives/"><span class="fa fa-book"></span></a></li>
          
            <li><a target="_blank" rel="noopener" href="https://github.com/Nimrod0901"><span class="fa fa-github-alt"></span></a></li>
          
        </ul>
	    
      <hr/>
      <div id="footerContent" class="footer-content">
        

      </div>
    </footer>

      








<script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>



  
<script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>




<script src="/js/typing.js"></script>

<!--[if lt IE 9]>
<script src="https://cdn.jsdelivr.net/npm/html5shiv@3/dist/html5shiv.min.js"></script>
<![endif]-->







    </div>
  </body>
</html>
